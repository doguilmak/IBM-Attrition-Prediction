# -*- coding: utf-8 -*-
"""IBM_attrition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1C3gRuw0Mq2x81prbMfWgXa3ZVrDlb4hy

**<h1 align=center><font size = 5>Attrition Prediction with Artificial Neural Networks</font></h1>**

<br>

<img src="https://raw.githubusercontent.com/Masterx-AI/Project_Attrition_Analysis_for_IBM/main/ibm.jpg" alt="IBM">

<small>Picture Source:<a href="https://raw.githubusercontent.com/Masterx-AI/Project_Attrition_Analysis_for_IBM/main/ibm.jpg">Attrition Analysis for IBM</a>

<br>

<h2>Description</h2>

<p>IBM is an American MNC operating in around 170 countries with major business verticals as computing, software, and hardware.
Attrition is a major risk to service-providing organizations where trained and experienced people are the assets of the company. The organization would like to identify the factors which influence the attrition of employees.</p>

<br>

<h2>Acknowledgements</h2>

<p>This dataset has been referred from <a href="https://www.kaggle.com/yasserh/ibm-attrition-dataset">Kaggle</a>.</p>

<br>

<h2>Objective:</h2>

<ul>
  <li>Understand the Dataset & cleanup (if required).</li>
  <li>Build classification models to predict the anticipated attrition of employees.</li>
  <li>Also fine-tune the hyperparameters & compare the evaluation metrics of various classification algorithms.</li>
</ul>

<br>

<h2>Keywords</h2>

<ul>
  <li>Tabular Data</li>
  <li>Classification</li>
  <li>Employment</li>
  <li>Artificial Neural Networks</li>
</ul>

<br>

# Objective for this Notebook

Within the scope of this project, a classification model was builded whether NEOs are dangerous or not, through data obtained from NASA.

<div class="alert alert-block alert-info" style="margin-top: 20px">
<li><a href="https://#data_preprocessing">Data Preprocessing</a></li>
<li><a href="https://#keras">Keras</a></li>
<li><a href="https://#build_a_neural_network">Build a Neural Network</a></li>
<li><a href="https://#mean_squared_error">Mean Squared Error</a></li>
<li><a href="https://#prediction">Prediction</a></li>
<br>

<p></p>
Estimated Time Needed: <strong>20 min</strong>
</div>

<br>

<a id="data_preprocessing"></a>

<h2 align=center>Data Preprocessing</h2>
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

concrete_data = pd.read_csv('IBM.csv')
concrete_data.head()

concrete_data.shape

concrete_data.describe()

concrete_data.isnull().sum()

print("Number of NaN values: {}.".format(concrete_data.isnull().sum().sum()))

print("Number of duplicated rows: {}.".format(concrete_data.duplicated().sum()))

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
concrete_data["EducationField"] = le.fit_transform(concrete_data['EducationField'])
concrete_data["MaritalStatus"] = le.fit_transform(concrete_data['MaritalStatus'])
concrete_data["Attrition"] = le.fit_transform(concrete_data['Attrition'])
concrete_data["Department"] = le.fit_transform(concrete_data['Department'])

concrete_data.head(10)

# Creating correlation matrix heat map
plt.figure(figsize = (17, 17))
sns.heatmap(concrete_data.corr(), annot = True)

sns.pairplot(concrete_data)
plt.show()

import matplotlib.patheffects as path_effects

explode = (0, 0.05)
fig = plt.figure(figsize = (10, 17), facecolor='w')
out_df=pd.DataFrame(concrete_data.groupby('Attrition')['Attrition'].count())

patches, texts, autotexts = plt.pie(out_df['Attrition'], autopct='%1.1f%%',
                                    textprops={'color': "w"},
                                    explode=explode,
                                    startangle=90, shadow=True)

for patch in patches:
    patch.set_path_effects({path_effects.Stroke(linewidth=2.5,
                                                foreground='w')})
plt.title('Target Variable Distribution')
plt.legend(labels=['No','Yes'], bbox_to_anchor=(1., .95), title="Attrition")

concrete_data_columns = concrete_data.columns

target = concrete_data["Attrition"]
predictors = concrete_data.drop(["Attrition"], axis=1)

target.head()

predictors.head()

n_cols = predictors.shape[1]
n_cols

"""<br>

<a id="keras"></a>

<h2 align=center>Keras</h2>

Recall from the videos that Keras normally runs on top of a low-level library such as TensorFlow. This means that to be able to use the Keras library, you will have to install TensorFlow first and when you import the Keras library, it will be explicitly displayed what backend was used to install the Keras library. In CC Labs, we used TensorFlow as the backend to install Keras, so it should clearly print that when we import Keras.
"""

import warnings
warnings.filterwarnings("ignore")
import keras

from keras.models import Sequential
from keras.layers import Dense

"""<br>

<a id="build_a_neural_network"></a>

<h2 align=center>Build a Neural Network</h2>

<p>Define a function that defines our regression model for us so that we can conveniently call it to create our model.</p>
"""

def regression_model():
    # 1-Create model
    model = Sequential()   
    model.add(Dense(8, activation="relu", input_shape=(n_cols,))) 
    # Creating second hidden layer:
    model.add(Dense(16, activation="relu"))
    # Creating output layer:
    model.add(Dense(1, activation="sigmoid"))
    
    # 2-Compile model
    model.compile(optimizer='adam', loss='mean_squared_error')
    return model

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=42)

model = regression_model()

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
model_history = model.fit(predictors, target, epochs=64, batch_size=32, validation_split=0.13)

loss_val = model.evaluate(X_test, y_test)
y_pred = model.predict(X_test)
loss_val

model_history.history.keys()

model.summary()

plt.figure(figsize=(15, 10))
sns.set_style('whitegrid')
plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc='upper left')

plt.figure(figsize=(15, 10))
sns.set_style('whitegrid')
plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('Model Loss')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'test'], loc='upper left')

"""### Saving the model"""

model.save('model.h5')

"""___

<a id="mean_squared_error"></a>

<h2 align=center>Mean Squared Error</h2>

<p>In statistics, the mean squared error (MSE) or mean squared deviation (MSD) of an estimator (of a procedure for estimating an unobserved quantity) measures the average of the squares of the errors—that is, the average squared difference between the estimated values and the actual value. MSE is a risk function, corresponding to the expected value of the squared error loss.</p>

$$\sum_{i=1}^{D}(x_i-y_i)^2$$
"""

from sklearn.metrics import mean_squared_error

mean_square_error = mean_squared_error(y_test, y_pred)
mean = np.mean(mean_square_error)
standard_deviation = np.std(mean_square_error)
print(f"Mean: {mean}\nStandard Deviation: {standard_deviation}")

total_mean_squared_errors = 64
epochs = 64
mean_squared_errors = []
for i in range(0, total_mean_squared_errors):
    X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.3, random_state=i)
    model.fit(X_train, y_train, epochs=epochs, verbose=0)
    MSE = model.evaluate(X_test, y_test, verbose=0)
    y_pred = model.predict(X_test)
    mean_square_error = mean_squared_error(y_test, y_pred)
    mean_squared_errors.append(mean_square_error)

mean_squared_errors = np.array(mean_squared_errors)
mean = np.mean(mean_squared_errors)
standard_deviation = np.std(mean_squared_errors)

print("\n" + str(total_mean_squared_errors) + " mean squared errors without normalized data. Total number of epochs for each training is: " + str(epochs) + "\n")
print("Mean: "+ str(mean))
print("Standard Deviation: "+ str(standard_deviation))

"""<br>

<a id="prediction"></a>

<h2 align=center>Prediction</h2>
"""

y_pred = model.predict(X_test)
y_pred = (y_pred > 0.5)

"""### System success on confusion matrix"""

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_pred)  #  Comparing results
print("Confusion Matrix:\n", cm)

"""### Accuracy score"""

from sklearn.metrics import accuracy_score
print(f"\nAccuracy score: {accuracy_score(y_test, y_pred)}")

"""### Making prediction from predictors DataFrame"""

predict = predictors[1:2]
prediction = model.predict(predict)

# İf predcition value is closter to the 0, that means it is most likely to be No.
# İf predcition value is closter to the 1, that means it is most likely to be Yes.

if prediction <= 0.5:
    print('\nModel predicted as No.')
else:
    print('\nModel predicted as Yes.')

class_map = {0: "No", 
            1: "Yes"}

target_model = target[1:2].iloc
print(f'\nActual attrition: {class_map[int(target_model[0])]}.')

"""<br>

<h1>Contact Me<h1>
<p>If you have something to say to me please contact me:<p>

<ul>
  <li>Twitter: https://twitter.com/Doguilmak</li>
  <li>Mail address: doguilmak@gmail.com</li>
</ul>
"""